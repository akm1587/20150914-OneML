{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lda\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack, csr_matrix, coo_matrix\n",
    "from nltk import classify\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from stemming.porter2 import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean up strings by replacing contractions, similar words\n",
    "\n",
    "def cleanstrings(x):\n",
    "    x = str(x)\n",
    "    x=x.lower()\n",
    "    in_strings = [\"can't\", \"couldn't\", \"hasn't\", \"haven't\", \"wasn't\", \"weren't\", \"won't\", \"didn't\", \"doesn't\", \"don't\", \"'ve\", \"i'm\"\n",
    "                  , \"sign-in\", \"sign in\", \"sing-on\", \"signon\", \"sign on\", \"365\"]\n",
    "    replace_strings = [\"cannot\", \"could not\", \"has not\", \"have not\", \"was not\", \"were not\", \"will not\", \"did not\", \"does not\",\n",
    "                       \"do not\", \" have\", \"I am\", \"signin\", \"signin\" , \"signin\", \"signin\", \"signin\", \"threesixtyfive\"]\n",
    "    for i in range(len(in_strings)):\n",
    "        x = x.replace(in_strings[i], replace_strings[i])\n",
    "    x = re.sub(\"[0-9!@#$%^&*()-_=+{[}]|\\:;,.<>?/]\", \" \", x)\n",
    "    #replace multiple spaces with one space\n",
    "    x = x.replace(' +', \" \")\n",
    "    #stem words\n",
    "    x = [\" \".join(stem(word) for word in x.split(\" \"))]\n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleandata = 0 # if cleandata = 1, then read in raw data and clean it, otherwise read stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cleandata==0:\n",
    "    dat = pd.read_csv(\"E:/oneml-office365-support/TrainCleaned.csv\", engine='python')\n",
    "    test_dat = pd.read_csv(\"E:/oneml-office365-support/TestCleaned.csv\", engine='python')\n",
    "else:\n",
    "    dat = pd.read_table('E:/oneml-office365-support/TrainingData.tsv', encoding='utf-8-sig')\n",
    "    test_dat = pd.read_table('E:/oneml-office365-support/TestingData.tsv', encoding='utf-8-sig')  \n",
    "    #run clean strings on ist fields, title, problem and error columns\n",
    "    dat['IST_1'] = dat.IST_1.apply(cleanstrings)\n",
    "    dat['IST_2'] = dat.IST_2.apply(cleanstrings)\n",
    "    dat['IST_3'] = dat.IST_3.apply(cleanstrings)\n",
    "    dat['title'] = dat.title.apply(cleanstrings)\n",
    "    dat['problem'] = dat.problem.apply(cleanstrings)\n",
    "    dat['error'] = dat.error.apply(cleanstrings)\n",
    "    #run clean strings on ist fields, title, problem and error columns\n",
    "    test_dat['IST_1'] = test_dat.IST_1.apply(cleanstrings)\n",
    "    test_dat['IST_2'] = test_dat.IST_2.apply(cleanstrings)\n",
    "    test_dat['IST_3'] = test_dat.IST_3.apply(cleanstrings)\n",
    "    test_dat['title'] = test_dat.title.apply(cleanstrings)\n",
    "    test_dat['problem'] = test_dat.problem.apply(cleanstrings)\n",
    "    test_dat['error'] = test_dat.error.apply(cleanstrings)\n",
    "    dat.to_csv(\"E:/oneml-office365-support/TrainCleaned.csv\", index=False)\n",
    "    test_dat.to_csv(\"E:/oneml-office365-support/TestCleaned.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#part of speech tagging\n",
    "postag = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''if postag == 0:\n",
    "    dat_pos = pd.read_csv(\"E:/oneml-office365-support/TrainPOS.csv\", engine='python')\n",
    "    test_pos = pd.read_csv(\"E:/oneml-office365-support/TestPOS.csv\", engine='python')\n",
    "else:\n",
    "    dat = pd.read_table('E:/oneml-office365-support/TrainingData.tsv', encoding='utf-8-sig')\n",
    "    test_dat = pd.read_table('E:/oneml-office365-support/TestingData.tsv', encoding='utf-8-sig')\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine CST_1 and CST_2 into a label column\n",
    "def getlabel(cols):\n",
    "    return cols.CST_1 + '||' + cols.CST_2\n",
    "\n",
    "dat['label'] = dat.apply(getlabel, axis=1)\n",
    "#test_dat['label'] = dat.apply(getlabel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dictionary to convert labels to numbers \n",
    "labeldf = dict(zip(dat.label.unique(), np.arange(len(dat.label.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat['labelind'] = [labeldf[x] for x in dat.label.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dictionaries from CST fields (note these aren't used later on)\n",
    "cst1_df = dict(zip(dat.CST_1.unique(), np.arange(len(dat.CST_1.unique()))))\n",
    "cst2_df = dict(zip(dat.CST_2.unique(), np.arange(len(dat.CST_2.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create features from the IST fields (these aren't used later on)\n",
    "ist1_df = dict(zip(dat.IST_1.unique(), np.arange(len(dat.IST_1.unique()))))\n",
    "ist2_df = dict(zip(dat.IST_2.unique(), np.arange(len(dat.IST_2.unique()))))\n",
    "ist3_df = dict(zip(dat.IST_3.unique(), np.arange(len(dat.IST_3.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat['ist1'] = [ist1_df[x] for x in dat.IST_1.values]\n",
    "dat['ist2'] = [ist2_df[x] for x in dat.IST_2.values]\n",
    "dat['ist3'] = [ist3_df[x] for x in dat.IST_3.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat['cst1'] = [cst1_df[x] for x in dat.CST_1.values]\n",
    "dat['cst2'] = [cst2_df[x] for x in dat.CST_2.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some problem fields are NaN. Replace those with empty strings\n",
    "dat.problem = dat.problem.fillna('')\n",
    "test_dat.problem = test_dat.problem.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get first sentence of 'problem' field and create features just based off of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def firstsentence(x):\n",
    "    return x.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat['first_sentence'] = dat.problem.apply(firstsentence)\n",
    "test_dat['first_sentence'] = test_dat.problem.apply(firstsentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainind = pd.read_csv(\"E:/oneml-office365-support/trainind.csv\", header=None)\n",
    "trainind = trainind.ix[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trainind = np.random.rand(len(dat)) < 0.7\n",
    "train = dat[trainind]\n",
    "test = dat[~trainind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.Series(trainind).to_csv(\"E:/oneml-office365-support/trainind.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CST_1', 'CST_2', 'IST_1', 'IST_2', 'IST_3', 'title', 'problem', 'error', 'SRId', 'label', 'labelind', 'ist1', 'ist2', 'ist3', 'cst1', 'cst2', 'first_sentence'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-80-d1b74dd4d42d>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-80-d1b74dd4d42d>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    cv = TfidfVectorizer(max_df=0.5 min_df=0.0005)\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#transform the data using TFidf. This function takes in a training set and a testing set. The training set is used to fit the TF\n",
    "# IDF vectorizer, and then it is applied to the test set fields. Both train and test results are outputted\n",
    "\n",
    "def tfidftransform(train, test, min_df=0.0005):\n",
    "    #cv = TfidfVectorizer(stop_words='english', min_df=0.0005)\n",
    "    cv = TfidfVectorizer(max_df=0.5 min_df=0.0005)\n",
    "    cv.fit(train.label)\n",
    "    #\n",
    "    probmat = cv.transform(train.problem.fillna(''))\n",
    "    probmat_test = cv.transform(test.problem.fillna(''))\n",
    "    #\n",
    "    probmat2= cv.fit_transform(train.problem.fillna(''))\n",
    "    probmat2_test = cv.transform(test.problem.fillna(''))\n",
    "    #\n",
    "    #first = cv.fit_transform(train.first_sentence)\n",
    "    #first_test = cv.transform(test.first_sentence)\n",
    "    first = cv.fit_transform(train.problem)\n",
    "    first_test = cv.transform(test.problem)\n",
    "    #\n",
    "    ist_1 = cv.fit_transform(train.IST_1.fillna(''))\n",
    "    ist_1_test = cv.transform(test.IST_1.fillna(''))\n",
    "    #\n",
    "    ist_2 = cv.fit_transform(train.IST_2.fillna(''))\n",
    "    ist_2_test = cv.transform(test.IST_2.fillna(''))\n",
    "    #\n",
    "    ist_3 = cv.fit_transform(train.IST_3.fillna(''))\n",
    "    ist_3_test = cv.transform(test.IST_3.fillna(''))\n",
    "    #\n",
    "    title = cv.fit_transform(train.title.fillna(''))\n",
    "    title_test = cv.transform(test.title.fillna(''))\n",
    "    #\n",
    "    error = cv.fit_transform(train.error.fillna(''))\n",
    "    error_test = cv.transform(test.error.fillna(''))\n",
    "    X = hstack((probmat, probmat2, first, ist_1, ist_2, ist_3, title, error))\n",
    "    X_test = hstack((probmat_test, probmat2_test, first_test, ist_1_test, ist_2_test, ist_3_test, title_test, error_test))\n",
    "    return X, X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = tfidftransform(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = train.label\n",
    "y_test = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over regularization constants to tune logistic regression\n",
    "#reg_const = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]#, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "#reg_const = [0.4]\n",
    "#for i in reg_const:\n",
    "#    model = LogisticRegression(C=i)\n",
    "#    model.fit(X,y)\n",
    "#    train_acc = model.score(X, y)\n",
    "#    cv_acc = model.score(X_test, y_test)\n",
    "#    print(i, train_acc, cv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.689826703056 0.629892798665\n"
     ]
    }
   ],
   "source": [
    "#predictions for CV with tuned regularization parameter\n",
    "model = LogisticRegression(C=0.4)\n",
    "model.fit(X_train,y)\n",
    "train_acc = model.score(X_train, y)\n",
    "cv_acc = model.score(X_test, y_test)\n",
    "print(train_acc, cv_acc)\n",
    "dm_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(dm_preds).to_csv(\"E:/oneml-office365-support/dm_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dm_preds = pd.read_csv(\"E:/oneml-office365-support/dm_preds.csv\", header=None)\n",
    "#dm_preds = dm_preds.ix[:,1].values\n",
    "#dm_preds_new = [labeldf[x] for x in dm_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.Series(dm_preds_new).to_csv(\"E:/oneml-office365-support/dm_preds_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###train on total training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_out = tfidftransform(dat, test_dat)\n",
    "y = dat.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684533957845\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.4)\n",
    "model.fit(X,y)\n",
    "train_acc = model.score(X, y)\n",
    "print(train_acc)\n",
    "final_dm_preds = model.predict(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitlabel(x):\n",
    "    return x.split(\"||\")\n",
    "\n",
    "final_dm_labels = pd.Series(final_dm_preds).apply(splitlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finaldf = pd.DataFrame()\n",
    "finaldf['SRId'] = test_dat.SRId\n",
    "cst1 = []\n",
    "cst2 = []\n",
    "for i in range(len(final_dm_labels)):\n",
    "    cst1.append(final_dm_labels[i][0])\n",
    "    cst2.append(final_dm_labels[i][1])\n",
    "finaldf['CST_1'] = cst1\n",
    "finaldf['CST_2'] = cst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finaldf.to_csv(\"E:/oneml-office365-support/submission_codalab_09_23.tsv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try heiarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909748457267 0.898822947882\n"
     ]
    }
   ],
   "source": [
    "#first train model to predict CST_1\n",
    "y_1 = train.CST_1\n",
    "y_1_test = test.CST_1\n",
    "model = LogisticRegression(C=0.4)\n",
    "model.fit(X_train, y_1)\n",
    "train_acc = np.mean(model.predict(X_train)==y_1)\n",
    "cv_acc = np.mean(model.predict(X_test)==y_1_test)\n",
    "print(train_acc, cv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_class_1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(pred_class_1).to_csv(\"E:/oneml-office365-support/pred_class_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_csr = X_train.tocsr()\n",
    "X_csr_test = X_test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O365 User and Domain Mgmt 0.718057022175 4735\n",
      "Exchange Online 0.574814535395 15906\n",
      "Office Pro Plus for O365 0.709060213844 1777\n",
      "SharePoint Online 0.589852880517 7273\n",
      "Lync and Skype Online 0.820388349515 2678\n"
     ]
    }
   ],
   "source": [
    "#Train a model for each CST_1\n",
    "model = LogisticRegression(C=0.4)\n",
    "unique_cst_1 = dat.CST_1.unique()\n",
    "tot_correct = 0\n",
    "hm_preds = np.zeros(len(test))\n",
    "for cst in unique_cst_1:\n",
    "    index = np.where(train.CST_1==cst)[0]\n",
    "    index2 = np.where(pred_class_1 == cst)[0]\n",
    "    y_1 = train.labelind.values[index]\n",
    "    y_1_test = test.labelind.values[index2]\n",
    "    model.fit(X_csr[index], y_1)\n",
    "    cv_acc = model.score(X_csr_test[index2], y_1_test)\n",
    "    hm_preds[index2] = model.predict(X_csr_test[index2])\n",
    "    tot_correct += cv_acc*len(index2)\n",
    "    print(cst, cv_acc, len(index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.Series(hm_preds).to_csv(\"E:/oneml-office365-support/hm_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62683431678457779"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_correct/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O365 User and Domain Mgmt', 'Exchange Online',\n",
       "       'Office Pro Plus for O365', 'SharePoint Online',\n",
       "       'Lync and Skype Online'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cst_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dm_preds_new = np.array([labeldf[x] for x in dm_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_preds = np.zeros(len(hm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_index = (pred_class_1 == \"Exchange Online\") | (pred_class_1 == \"SharePoint Online\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_preds[replace_index] = dm_preds_new[replace_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_preds[~replace_index] = hm_preds[~replace_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63075782384380119"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(final_preds==test.labelind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62683431678457779"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hm_preds==test.labelind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62989279866538972"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dm_preds_new==test.labelind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
